import tkinter as tk
from tkinter import messagebox
import cv2
import os
from PIL import Image
import numpy as np
import mysql.connector
from tkinter import *
from imageai.Detection import ObjectDetection
from PIL import ImageTk,Image


root=tk.Tk()
root.title("Face Login and Object Identification")


l1 = tk.Label(root, text="Name", font=("Script MT Bold",15,"italic"), fg="#0E0C0A")
l1.grid(column=0, row=0)
t1 = tk.Entry(root, width=40, bd=2)
t1.grid(column=1, row=0)

l2 = tk.Label(root, text="Age", font=("Script MT Bold",15,"italic"), fg="#0E0C0A")
l2.grid(column=0, row=1)
t2 = tk.Entry(root, width=40, bd=2)
t2.grid(column=1, row=1)

l3 = tk.Label(root, text="Address", font=("Script MT Bold",15,"italic"), fg="#0E0C0A")
l3.grid(column=0, row=2)
t3 = tk.Entry(root, width=40, bd=2)
t3.grid(column=1, row=2)

# Train Classifier Function

def train_classifier():
    data_dir="D:/AppDevelopment/data"
    path = [os.path.join(data_dir,f) for f in os.listdir(data_dir)]
    faces  = []
    ids   = []
    
    for image in path:
        img = Image.open(image).convert('L');
        imageNp= np.array(img, 'uint8')
        id = int(os.path.split(image)[1].split(".")[1])

        faces.append(imageNp)
        ids.append(id)
    ids = np.array(ids)
    
    #Train the classifier and save
    clf = cv2.face.LBPHFaceRecognizer_create()
    clf.train(faces,ids)
    clf.write("classifier.xml")
    messagebox.showinfo('Result','Training dataset completed!!!')

# Training Model Button

b1 = tk.Button(root, text="Training", font=("MS San Serif",20,"italic"),bg="#F9FFF8",fg="Black", borderwidth=2, relief="solid",command=train_classifier)
b1.grid(column=0, row=4)

# Face Detection from Database Function

def detect_face():

    # Face Boundaries Function

    def draw_boundary(img,classifier,scaleFactor,minNeighbors,color,text,clf):
        gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        features = classifier.detectMultiScale(gray_image,scaleFactor,minNeighbors)

        coords = []

        for(x,y,w,h) in features:
            cv2.rectangle(img,(x,y),(x+w,y+h),color,2)
            id,pred = clf.predict(gray_image[y:y+h,x:x+w])
            confidence = int(100*(1-pred/300))
            
            mydb=mysql.connector.connect(
            host="localhost",
            user="root",
            passwd="",
            database="authorized_user"
            )
            mycursor=mydb.cursor()
            mycursor.execute("select name from my_table where id="+str(id))
            s = mycursor.fetchone()
            s = ''+''.join(s)
            
            if confidence>74:
                cv2.putText(img,s,(x,y-5),cv2.FONT_HERSHEY_SIMPLEX,0.8,color,1,cv2.LINE_AA)   
            else:
                cv2.putText(img,"UNKNOWN",(x,y-5),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,0,255),1,cv2.LINE_AA)

            coords=[x,y,w,h]
        return coords

# Face Recognition Function
            
    def recognize(img,clf,faceCascade):
        coords = draw_boundary(img,faceCascade,1.1,10,(255,255,255),"Face",clf)
        return img

    faceCascade=cv2.CascadeClassifier("haarcascade_frontalface_default.xml")
    clf = cv2.face.LBPHFaceRecognizer_create()
    clf.read("classifier.xml")

    video_capture =  cv2.VideoCapture(0)

    while True:
        ret,img = video_capture.read()
        img=  recognize(img,clf,faceCascade)
        cv2.imshow("face detection",img)

        if cv2.waitKey(1)==13:
            break

    video_capture.release()
    cv2.destroyAllWindows()

# Button for Face Detection

b2 = tk.Button(root, text="Detect the faces", font=("MS San Serif",20,"italic"), bg="#89CFF0", fg="Black", borderwidth=2, relief="solid", command=detect_face)
b2.grid(column=1, row=4)

# Face Dataset Embedding Function

def generate_dataset():
    if(t1.get()=="" or t2.get()=="" or t3.get()==""):
        messagebox.showinfo('Result','Please provide complete details of the user')
    else:
        mydb=mysql.connector.connect(
        host="localhost",
        user="root",
        passwd="",
        database="authorized_user"
        )
        mycursor=mydb.cursor()
        mycursor.execute("SELECT * from my_table")
        myresult=mycursor.fetchall()
        id=1
        for x in myresult:
            id+=1
        sql="insert into my_table(id,Name,Age,Address) values(%s,%s,%s,%s)"
        val=(id,t1.get(),t2.get(),t3.get())
        mycursor.execute(sql,val)
        mydb.commit()
        
        face_classifier = cv2.CascadeClassifier("haarcascade_frontalface_default.xml")
        def face_cropped(img):
            gray  = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            faces = face_classifier.detectMultiScale(gray,1.3,5)


            if faces is ():
                return None
            for(x,y,w,h) in faces:
                cropped_face=img[y:y+h,x:x+w]
            return cropped_face

        cap = cv2.VideoCapture(0)
        img_id=0

        while True:
            ret,frame = cap.read()
            if face_cropped(frame) is not None:
                img_id+=1
                face = cv2.resize(face_cropped(frame),(200,200))
                face  = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)
                file_name_path = "data/user."+str(id)+"."+str(img_id)+".jpg"
                cv2.imwrite(file_name_path,face)
                cv2.putText(face,str(img_id),(50,50),cv2.FONT_HERSHEY_COMPLEX,1, (0,255,0),2)


                cv2.imshow("Cropped face",face)
                if cv2.waitKey(1)==13 or int(img_id)==200:
                    break
        cap.release()
        cv2.destroyAllWindows()
        messagebox.showinfo('Result','Dataset completed!!!')

b3 = tk.Button(root, text="Generate dataset", font=("MS San Serif",20,"italic"), bg="#F4C2C2", fg="black", borderwidth=2, relief="solid", command=generate_dataset)
b3.grid(column=2, row=4)


# Image Capture Function

def capture_image():
    key=cv2.waitKey(1)
    cap=cv2.VideoCapture(0)  # capturing image from web video camera
    while True:
        try:
            check,frame=cap.read()
            print(check,frame)      # print it as web cam is on screen
            cv2.imshow("Capturing Image...", frame)
            key=cv2.waitKey(1)
            if key == ord("c"):
                cv2.imwrite(filename="save_img.jpg", img = frame)
                cap.release()
                img_new = cv2.imread("save_img.jpg", cv2.IMREAD_GRAYSCALE)
                img_new = cv2.imshow("Click Image..",img_new)
                cv2.waitKey(1650)
                cv2.destroyAllWindows()
                print("Working on Iamge...")
                img_= cv2.imread("save_img.jpg", cv2.IMREAD_ANYCOLOR)
                print("Please Wait!!! Image is processing...")
                print("Image is Done Processing")
                gray=cv2.cvtColor(img_, cv2.COLOR_BGR2GRAY)         # converting Color image to grayscale image
                print("Cnverted RGB To Grayscale")
                print("Resizing Image...")
                img_=cv2.resize(gray,(500,500))             # resizing image
                img_resized=cv2.imwrite(filename="gray_img.jpg",img=img_)
                print("Image Successfully Saved")
                break

            elif key == ord("q"):
                print("Turning Web Camera Off...")
                cap.release()
                print("Camera Off Successfully")
                cv2.destroyAllWindows()
        except(KeyboardInterrupt):
            print("Turning Web Camera Off!!!!")
            cap.release()
            print("Camera off Successfully")
            print("NO IMAGE IS CAPTURED!!!")
            cv2.destroyAllWindows()
            break

# Capturing Image Button

b4=tk.Button(root, text="Object Detection", font=("MS San Serif",20,"italic"), bg="#F4C2C2", fg="Black", borderwidth=2, relief="solid", command=capture_image)
b4.grid(row=5, column=2)

# object detection classifier Function

def train_object():
    execution_path = os.getcwd()

    detect = ObjectDetection()
    detect.setModelTypeAsRetinaNet()
    detect.setModelPath( os.path.join(execution_path , "resnet50_coco_best_v2.1.0.h5"))
    detect.loadModel()
    detections = detect.detectObjectsFromImage(input_image=os.path.join(execution_path , "save_img.jpg"), output_image_path=os.path.join(execution_path , "imagenew.jpg"))
    print("Processing Intput Image")
    for imge in detections:
        print(imge["name"] , " : " , imge["percentage_probability"] )
        print("Done Processing")

# Training Object Model Button

b5 = tk.Button(root, text="Train Object", font=("MS San Serif",20,"italic"),bg="#F9FFF8",fg="Black", borderwidth=2, relief="solid",command=train_object)
b5.grid(column=0, row=5)


# Open Capture Image Function

def open_image():
    im = Image.open("imagenew.jpg") 
    im.show()

# Open Image Button

b6 = tk.Button(root, text="Open Image", font=("MS San Serif",20,"italic"), bg="#89CFF0", fg="Black", borderwidth=2, relief="solid", command=open_image)
b6.grid(row=5,column=1)



root.geometry("800x250")
root.mainloop()
